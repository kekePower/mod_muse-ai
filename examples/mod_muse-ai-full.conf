# mod_muse-ai Phase 3 Advanced Configuration Example
# This configuration showcases all the advanced features implemented in Phase 3

# Load the module
LoadModule muse_ai_module modules/mod_muse_ai.so

# Basic Configuration (Phase 1 & 2)
MuseAiEndpoint https://api.openai.com/v1
MuseAiApiKey "sk-proj-0000000000000000000000000000000000000000000000000000000000000000"
MuseAiModel gpt-4.1-nano
MuseAiTimeout 300
MuseAiDebug On
MuseAiStreaming On
MuseAiMaxTokens 16384

# Connection Pooling
MuseAiPoolMaxConnections 20
MuseAiPoolConnectionTimeout 300
MuseAiPoolIdleTimeout 60
MuseAiPoolEnableKeepAlive On

# Caching
MuseAiCacheEnable On
MuseAiCacheTTL 300
MuseAiCacheMaxEntries 1000
MuseAiCacheKeyPrefix "muse_ai_"

# Rate Limiting
MuseAiRateLimitEnable On
MuseAiRateLimitRPM 120
MuseAiRateLimitBurstSize 20
MuseAiRateLimitWhitelistIPs "127.0.0.1,::1"

# Performance Monitoring
MuseAiMetricsEnable On
MuseAiMetricsEndpoint "/metrics"
MuseAiMetricsIncludeRequestDetails Off

# Reasoning Models Support
MuseAiReasoningModelPattern "deepseek-r1"
MuseAiReasoningModelPattern "deepseek"
MuseAiReasoningModelPattern "gemini-2.5-flash"
MuseAiReasoningModelPattern "qwen"
MuseAiReasoningDisableThinking On

# Advanced Streaming
# Note: StreamingBufferSize is now automatically calculated from MuseAiMaxTokens
MuseAiStreamingChunkSize 2048
MuseAiStreamingSanitizationEnable On

# Security
MuseAiSecurityValidateContentType On
MuseAiSecurityMaxRequestSize 2097152  # 2MB
MuseAiSecurityAllowedOrigins "*"

# Load Balancing (Multiple backends)
MuseAiBackendEndpoint http://127.0.0.1:11434/v1
MuseAiBackendEndpoint http://127.0.0.1:11435/v1
MuseAiBackendEndpoint http://127.0.0.1:11436/v1
MuseAiLoadBalanceMethod round_robin
MuseAiHealthCheckInterval 30

# Timeouts and Retries
MuseAiConnectTimeout 15
MuseAiReadTimeout 300
MuseAiWriteTimeout 30
MuseAiMaxRetries 3
MuseAiRetryDelayMs 1000

# Virtual Host Configuration
<VirtualHost *:80>
    ServerName ai.example.com
    DocumentRoot /var/www/html
    
    # Main AI endpoint
    <Location "/ai">
        SetHandler muse-ai-handler
    </Location>
    
    # Metrics endpoint
    <Location "/metrics">
        SetHandler muse-ai-metrics
        # Restrict access to metrics
        Require ip 127.0.0.1
        Require ip ::1
    </Location>
    
    # Health check endpoint
    <Location "/health">
        SetHandler muse-ai-health
    </Location>
    
    # Status page with advanced features
    <Location "/status">
        SetHandler muse-ai-status
    </Location>
    
    # Custom error pages
    ErrorDocument 429 "Rate limit exceeded. Please try again later."
    ErrorDocument 503 "AI service temporarily unavailable."
    
    # Logging
    LogLevel info
    CustomLog logs/muse_ai_access.log combined
    ErrorLog logs/muse_ai_error.log
</VirtualHost>

# Performance Tuning
# Increase worker limits for AI workloads
ServerLimit 16
MaxRequestWorkers 400
ThreadsPerChild 25

# Memory and timeout settings
LimitRequestBody 10485760  # 10MB max request size
Timeout 600               # 10 minute timeout for long AI responses

# Enable compression for metrics and status endpoints
LoadModule deflate_module modules/mod_deflate.so
<Location "/metrics">
    SetOutputFilter DEFLATE
</Location>
<Location "/status">
    SetOutputFilter DEFLATE
</Location>
